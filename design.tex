\chapter{Design} \label{design}

\section{Design Specification}
What are our system specs?

\section{System Overview}
Our wireless stethoscope consists of seven subsystems in order to transfer the auscultation sound signal to a speaker (Fig~\ref{fig:sys_overview}), they are
\begin{itemize}
	\item Signal sensor,
	\item Signal amplification,
	\item Input circuitry,
	\item Signal processing,
	\item Wireless transmission,
	\item Wired transmission,
	\item System power.
\end{itemize}

\begin{figure}[!ht]
	\centering
	
		\includegraphics[resolution=120, width=315px, height=315px]{sys_overview2.png}
	
	\caption{System overview}
	\label{fig:sys_overview}
\end{figure}

The sensor consists of a conventional stethoscope head coupled to a microphone, which transforms the sound signal into a voltage signal. This signal is too small to drive any circuitry directly, so it is passed through a signal amplification stage, which results in a bipolar signal. After amplification the signal is passed through input circuitry which introduces a 1.65V offset and limits the voltage to within the maximum tolerable values of the micro-controller in the next stage. This offset is required to transform the signal from bipolar to unipolar, as the micro-controller can not read negative voltages. The micro-controller then performs signal processing in the form of a digital filter, so that it will have the same sound characteristics as a conventional stethoscope. Once processed the signal is transmitted to a Blue-tooth module which transmits the data to a Blue-tooth speaker. In addition an audio jack is available to plug in a speaker directly. All these subsystems are powered by a 9V power source, which can be switched between battery and an AC-DC wall adapter.

\section{Signal Sensor}
Why we chose microphone vs. laser mic, vs. cap sensor \\
How we coupled microphone to stethoscope \\
Microphone circuit



\section{Signal Amplification}
To amplify the microphone signal we used an instrumentation amplifier, followed by a Low Pass Filter (LPF), and then two non-inverting amplifiers.
The instrumentation amplifier (Fig.~\ref{fig:inamp_circuit}) was used to get an accurate measurement of the microphone signal. It does so because it acts as a difference amplifier with a large Common Mode Rejection Ratio (CMMR), which allows it to significantly reject any noise present on the ground plane\cite[p.~86]{Franco2015}, leaving only the microphone signal. 
\begin{figure}[!htb]
	\centering
	\fbox{
		\includegraphics[width=130mm]{instrument_amp_circuit.png}
	}
	\caption{Instrumentation Amplifier circuit used to pick up signal from microphone}
	\label{fig:inamp_circuit}
\end{figure}
This signal is then passed through a LPF to suppress any signal above 20kHz, which is necessary to prevent aliasing in the ADC process of the signal processing stage. The LPF (Fig.~\ref{fig:LPF_circuit}) is implemented by using a second order Sallen-Key configuration\cite[p.~279]{Horowitz1989} and can be designed for different cut-off frequencies through resistor and capacitor values C1, C2, R12, and R13. 
\begin{figure}[!htb]
	\centering
	\fbox{
		\includegraphics[width=100mm]{LPF_circuit.png}
	}
	\caption{Low Pass Filter (LPF) circuit used to attenuate signals below 20kHz}
	\label{fig:LPF_circuit}
\end{figure}
Finally the two non-inverting amplifiers are used to amplify the signal (Fig.~\ref{fig:amplifier_circuit}). We used two amplifiers in series so that each individual amplifier may have a smaller gain. By having having lower gains the output resistors RA2 and RA3 are smaller, which results in less thermal, or ``Johnson'' noise, and thus a clear sound signal. We used non-inverting configuration because of its high input impedance. This effectively decouples the design from the preceding LPF stage as it does not load the output, making design of the amplification stage independent from the LPF. 
\begin{figure}[!htb]
	\centering
	\fbox{
		\includegraphics[width=130mm]{amplifier_circuit.png}
	}
	\caption{Amplification circuit used to increase sound signal}
	\label{fig:amplifier_circuit}
\end{figure}
We used LM318 op-amps for the instrumentation and non-inverting amplifiers because of its high gain-bandwidth product (15MHz) and slew rate (50$V/\mu s$), which allows for a larger gain without distorting the signal.

\section{Input Circuitry}
The input circuitry consists of a buffer, summer, and clipping circuit which transform the amplified signal into one that is appropriate for the micro-controller input. The buffer (Fig.~\ref{fig:buffer_circuit}) serves two purposes, firstly it blocks any DC offset introduced from the previous stages, and secondly it decouples these stages from the summing circuit. 
\begin{figure}[!htb]
	\centering
	\fbox{
		\includegraphics[width=100mm]{buffer_circuit.png}
	}
	\caption{Buffer circuit used to isolate input stage from amplification stage, taken from TI LM318 data-sheet\cite{TILM318}}
	\label{fig:buffer_circuit}
\end{figure}
The summing circuit (Fig.~\ref{fig:summing_circuit}) is used to add 1.65V to the signal. This is necessary because the ADC of the next stage can only accept voltages between 0V to 3.3V, and so can only handle a maximum voltage swing of 1.65V. This summer transforms input signals in the range $\pm1.65$V to the necessary ADC input range and allows for the maximum voltage swing to be measured without clipping, leading to less distortion of the auscultation signal. 
\begin{figure}[!htb]
	\centering
	\fbox{
		\includegraphics[width=130mm]{summing_circuit.png}
	}
	\caption{Summing circuit used to introduce 1.65V offset of signal coming into the micro-controller}
	\label{fig:summing_circuit}
\end{figure}
Finally the active clipping circuit (Fig.~\ref{fig:clipping_circuit}) is used to protect the micro-controller input. It does so by allowing all signals in the range 0V-3V to pass through, but clips any signal outside this range. This is necessary because it is likely that signals other than auscultation sounds may be amplified, such as the stethoscope diaphragm being knocked as it is placed on the patient. These unwanted signals may cause brief but large signals that could potentially damage the microprocessor input if left unmitigated. Thus the clipping circuit protects the micro-controller input by limiting the voltage passed through.

\begin{figure}[!htb]
	\centering
	\fbox{
		\includegraphics[width=130mm]{clipping_circuit.png}
	}
	\caption{Clipping circuit used to keep input voltage to micro-controller in the range 0-3.3V, taken from \cite[p.~221]{Horowitz1989}}
	\label{fig:clipping_circuit}
\end{figure}

We used an LM741 op-amp for all the circuits in the input-stage because it is the cheapest op-amp we know of. Its unity gain bandwidth of 1MHz is sufficient because these circuits don't amplify the signal, they only pass it through. By using these cheaper, ubiquitous op-amps we lower the cost of the overall system. 

Note that both the summing and clipping circuit also require the regulated 3.3V ($V_\text{regulated}$) to function, which is taken from the LM317 voltage regulator that is also used to power the microphone, Blue-tooth module, and micro-controller (Section~\ref{sys_power}).


\section{Signal Processing}
A micro-controller processes the sound signal using Infinite Impulse Response (IIR) and Finite Impulse Response (FIR) digital filters. This signal processing is used to filter out unstable feedback frequencies and to reproduce the sound characteristics of a conventional stethoscope. Unstable feedback occurs when the microphone sensor picks up the sound played through the speaker. It happens at specific resonant frequencies which depend on the length of the coupling tube, stethoscope diaphragm, and microphone (section \ref{feedback-freq}). If left untreated these unstable frequencies can grow in amplitude until the user can only hear a large squealing sound from the device, making auscultation impossible. The micro-controller further processes the signal in order to negate the effect that having a smaller coupling tube has on the transmitted sound. The tube length of the original stethoscope is approximately 50cm, while our design has a coupling tube of only 3cm. This difference in length changes the sound transmission properties of the tube, dampening sound frequencies by a different amounts. Negating this ``colouration'' effect helps reproduce the type of sounds doctors currently listen for with a conventional stethoscope.

\subsection{Microprocessor Requirements} \label{mcu-requirements}
In order to decide which microprocessor to use we need to first establish the minimum requirements. We consider the bus size, speed, and the amount of working memory needed to implement the digital filters.

Bus sizes for microprocessors generally come in 8, 16, and 32-bit. This bus size determines the bit-depth, which is number of bits stored per sample. A larger bit-depth will require more memory to store samples, however it will suffer less quantization noise, which is the result of truncation error inherent in ADC. For our system we used 16 bit bit-depth because that's the same used in CDs~\cite[p.~27]{Schroder2011}, and we assumed CD audio quality would be sufficient.

To determine how fast the processor needs to be we estimate how many Million Instructions Per Second (MIPS) that it has to execute. To perform this calculation we need the sampling frequency ($F_s$) and the order of the digital filter we wish to implement ($N$). We take $F_s$ to be 40kHz, the Nyquist frequency associated with 20kHz sounds. Although we require to capture sounds only up to 4kHz (Section~\ref{max-sound-freq}) we use the more conservative figure for flexibility to change the design in the future. The order of the filter $N$ was unknown at the time of purchasing the micro-controller, hence an estimate of $N=100$ is used, as our past experience with designing low pass digital filters found this to be a conservative estimate. $N^{th}$ order digital filters are typically calculated as~\cite[p.~164]{Mitra2011}
\begin{equation}
y[n] = p_0 x[n] + p_1 x[n-1] + \cdots + p_N x[n-N] - d_1 y[n-1] - \cdots - d_n y[n-N]
\label{eq:filter}
\end{equation}
where $y$ is the sampled output signal, $x$ is the sampled input signal, and $d_i, p_i$ are constant filter coefficients. This requires $2N$ additions and $2N$ multiplications, for a total of $4N$ instructions per output sample $y[n]$. In addition to the digital filter the controller must also transmit 16 bits of data per sample to the Blue-tooth module, giving a required speed of $(16+4N)F_s=(16+400)40\cdot10^3=16.64$ MIPS. Thus if we round up for safety then we require a processor capable of at least 17 MIPS.

The amount of working memory required is calculated by noting that the filter in Eq.~\ref{eq:filter} needs to store $2(N+1)$ coefficients $(p_i, d_i)$, $N+1$ input signal samples $(x)$ and $N+1$ output signal samples $(y)$, for a total of $4(N+1)=404$ 16 bit values, or 808 Bytes of RAM. We round this value up to the nearest KByte and double it as a safety margin to get a minimum requirement of 2KBytes of RAM.

In summary our micro-controller needs to be at least 16-bit, capable of 17 MIPS with at least 2KBytes of working memory.

\subsection{Microprocessors Considered}
We considered five microprocessors for the system, the Arduino nano, Raspberry Pi, ADSP-BF504 Blackfin processor from Analog Devices, and the dsPIC33-FJ64GP802 from Microchip. Each processor was scored in terms of its coding, interface, size, speed, and cost, and a weighted total score determined which processor to use. 

Coding relates to what programming language the processor can be coded in. Languages such as C and Python are considered higher level than Assembly for example, and are more desirable to code in because it is quicker to develop in these languages, which will help us meet the time constraints of the project. 

Interface describes how easy it is to upload a program to the device. We wish to have the unit programmable while in a circuit in order to minimise the time it takes to debug the hardware and software. If it has to be disconnect or unplugged from our circuit for each upload iteration this could be prohibitively time consuming. 

The size of the processor will affect the size of our stethoscope. If it is too large to be comfortably held in the hand then it will not have met its specifications, thus we require a processor that won't greatly increase the size of our final design.

Speed is constrained to be at least 17 MIPS (Section~\ref{mcu-requirements}), anything above this is considered a bonus as it allows for further flexibility in filter design. 

Finally we considered cost, by minimising the processor cost we minimise the cost of our final device and thus the likelihood of it being used or purchased.

From our weighted total scores we decided to use the dsPIC33-FJ64GP802 microprocessor (Table~\ref{mcu-decision-matrix}). In our scoring analysis we estimated the speed to be the clock frequency of the device, which meant the Adruino was not fast enough to perform the required filtering computation. The Raspberry pi provided the greatest speed however it was both the largest and most expensive option, which made it less feasible. The Blackfin BF504 also provided considerable speed however it was only sold in surface mount packages or as part of a development board, making it difficult to prototype onto a bread board. Thus because of its low cost, small form factor, and ability to handle the required computation we decided to use the dsPIC.
\input{./table/mcu_decision_matrix.tex}


\subsection{dsPIC33 micro-controller}
\subsubsection{Features}
We used a dsPIC33-FJ64GP802 microprocessor to process the sound signal. The chip contains an ADC, audio DAC and dedicated Digital Signal Processing (DSP) engine, which make it well suited to filter our signal. The DSP engine (Fig.~\ref{fig:dsp_block}) is capable of retrieving two words of data from memory, multiplying them and summing them to a running total in a single instruction cycle. This operation of Multiplying and ACcumulating (MAC) is frequently used in digital filters, and so being able to perform a MAC in a single cycle makes the chip efficient for our purposes. The ADC is capable of converting 500k 12-bit samples per second through successive approximation conversion, so it is fast enough to handle our maximum requirement of 40k samples per second. ADC conversions are also written directly to memory, without any CPU intervention, through the chip's Direct Memory Access (DMA) feature, resulting in less overhead and allowing the chip to execute more instructions per sample. Finally the DAC is designed specifically for audio applications, and is capable of producing up to 40kHz signals, making it suitable for our application as we wish to output a filtered sound signal. 

\begin{figure}[!ht]
	\centering
	\fbox{
		\includegraphics[width=130mm]{dsp_engine.png}
	}
	\caption{Micro-controller with DSP-engine and two address generator units to pre-fetch data for Multiply and Accumulate instruction (MAC). Taken from dsPIC33F data-sheet \cite[p.~14]{dspic_datasheet}}
	\label{fig:dsp_block}
\end{figure}

\subsubsection{Operation}
The dsPIC utilises two memory locations, buffers A and B, to apply the digital filter. In one cycle the ADC writes to buffer A, while the filter function operates on data in buffer B and outputs the result to the DAC (Fig.~\ref{fig:mcu_operation}). In the next cycle the ADC writes to buffer B while the filter is applied to buffer A samples. This ``ping-pong'' switching between the two buffers allows the ADC to sample data while the dsPIC simultaneously applies a digital filter to previous data samples, which results in a continuously filtered output signal. The filter is executed using the IIR and FIR functions of the DSP library that is included with Microchip's dsPIC Integrated Development Environment ``MPLABX''.

It is important to assure that the rate at which buffer's A and B are written to by the ADC and read from by the DAC are synchronized, otherwise the output signal will be distorted. If the ADC writes data at a different rate than the DAC reads it then the output signal will be shifted in frequency compared to the input signal. It is also possible for newer input samples to overwrite previous ones before they've been processed, corrupting that block of data. The time at which the ADC samples is controlled by an internal counter. The counter raises an interrupt after a programmed number of system clock cycles, which gives us great flexibility in setting the ADC sampling frequency. The DAC clock however is constrained to run off an auxiliary clock, scaled down by a selectable factor from between 1 to 128, which restricts what sampling frequencies we can use the most. Hence our sampling frequency for the system was set to 48kHz in order to satisfy the ADC/DAC synchronization condition.

\begin{figure}[!htb]
	\centering
	% \fbox{
		\includegraphics[width=90mm]{mcu_operation.png}
	% }
	\caption{Micro-controller uses two memory buffers to simultaneously sample and filter sound data}
	\label{fig:mcu_operation}
\end{figure}



\section{Wireless Transmission}
Yudong

\section{Wired Transmission}
Yudong

\section{System Power} \label{sys_power}
Yudong